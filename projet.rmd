---
title: "Projet"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

# Projet d'Analyse et de Fouille de Données Massive

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(FactoMineR)
```
## Introduction :
&ensp;Le but du projet est de manipuler différentes méthodes d'analyses de données sur un jeu de données constitué d'une centaine d'individus et d'une dizaine de variables qualitatives et quantitatives. Nous avons choisi comme jeu de données les vidéos présentes dans la catégorie "Tendances" du site YouTube France sur une période allant de novembre 2017 à juin 2018. La catégorie "Tendances" de YouTube met en évidence les vidéos les plus vues et les plus appréciées par les utilisateurs de la plateforme. Elle permet donc une plus grande visibilité pour les créateurs de contenu. Une vidéo est placée dans la catégorie "Tendances" par un algorithme se fondant sur les statistiques de la vidéo ainsi que sur les interactions des utilisateurs avec celle-ci. L'analyse des facteurs permettant à une vidéo d'être présente en "Tendances" peut donc être intéressante pour les vidéastes de la plateforme souhaitant être mis en avant. 

## Présentation de nos données :

&ensp;Nous avons extrait nos données du site Kaggle (https://www.kaggle.com/datasnaek/youtube-new). Ces données contiennent un ensemble de statistiques sur les vidéos de la catégorie "Tendances" de YouTube. Nous avons décidé d'extraire les statistiques qui nous paraissaient pertinentes pour pouvoir déterminer les facteurs influant sur la présence ou non d'une vidéo dans la catégorie "Tendances". Ces statistiques sont resumées dans le tableau suivant et seront utilisées comme variables qualitatives ou quantitatives dans les différentes méthodes d'analyse des données.

|                 Nom                |   Attribut  |
|:----------------------------------:|:-----------:|
|           Taux LOWER Case          | quantitatif |
|           Taux UPPER Case          | quantitatif |
|               Nb tags              | quantitatif |
|               Nb vues              | quantitatif |
|           Nb commentaires          | quantitatif |
|              Nb likes              | quantitatif |
|             Nb dislikes            | quantitatif |
|Taille de la  description (en mots) | quantitatif |
|              Catégorie             |  qualitatif |
| Jour de la semaine                 |  qualitatif |
|        Moment de la  journée       |  qualitatif |
|    Nombre de lien en description   | quantitatif |

&ensp;Nous pouvons nous attendre à une forte corrélation entre la présence d'une vidéo en "Tendances" et son nombre de vues, de "J'aime" et de commentaires. Néanmoins, d'autres variables peuvent influer de manière indirecte sur le nombre de vues comme le nombre de majuscules dans le titre, le nombre de tags associés à la vidéo ou encore la longueur de la description. La publication de la vidéo peut également être ciblée afin de toucher le plus de personnes possible (une vidéo publiée le vendredi soir à 18h aura probablement plus d'impact qu'une vidéo publiée le mardi matin à 8h). Nous serons également en mesure d'exhiber le type de vidéos qui plaisent au public français via la catégorie mais aussi de comparer les audiences des vidéos appartenant à différentes catégories (par exemple, les personnes regardant des vidéos sportives consultent également des vidéos de mode ou de divertissement). 

## Traitement du jeu de données
&ensp;A partir du jeu de données télechargé au format csv, nous avons généré un nouveau fichier csv contenant, pour chaque vidéo, les statistiques listées dans le tableau précédent Vous pouvez retrouver le code commenté pour l'extraction et le traitment des données brutes initiales dans le fichier 'processData.py'.

## Analyse des données
&ensp;Dans cette partie, nous allons analyser les données que nous avons extraites et qui se trouvent dans le fichier "youtubeTrends.csv". Ce fichier contient 40703 individus. Néanmoins les méthodes d'analyse détaillées dans cette partie ne porteront que sur une centaine d'invidus. Nous sélectionnons donc 100 vidéos de manière aléatoire dans le fichier "youtubeTrends.csv". Ces 100 vidéos seront utilisées comme individus pour les différentes méthodes d'analyse.  

Code pour selectionner les 100 individus aléatoirement :
```{r}
data = read.csv("./DATA/youtubeTrends.csv")
data = data[sample(nrow(data), 100),]
```

Code pour récupérer les 100 individus que nous avons selectionnés et sauvegardés :
```{r}
setwd("CHEMIN VERS LA RACINE DU DOSSIER CONTENANT LE RDATA")
load('./random_data.rdata')
```


### ACP
On récupère les données :




La première analyse que nous allons essayé sera une ACP, pour ce faire, il faut que l'on prépare nos données en retirant les données qualitatives que nous avons.
Ensuite On execute l'ACP sur nos données.
```{r}
# On retire les données qualitatives
data_ACP = data
data_ACP$category <- NULL
data_ACP$momentOfDay <- NULL
data_ACP$day <- NULL
data_ACP$index <- NULL

# On retire les données considéré comme faiblement corellé après les premiers tests 
data_ACP$nbTags <- NULL
data_ACP$nbWords <- NULL
data_ACP$nbLinks <- NULL

res.pca = PCA(data_ACP, scale.unit=TRUE, ncp=6, graph=T)
```

Sur la figure on peut voir que l'on représente bien les données X% sur l'axe 1 et Y% sur l'axe 2.
On voit que le nombre de like et dislike sont corrélé, après analyse, on se rend compte que ces deux variables ne capturent pas vraiment ce que l'on voulait. En effet

```{r}
# On retire les données qualitatives
data_ACP = data
data_ACP$category <- NULL
data_ACP$momentOfDay <- NULL
data_ACP$day <- NULL
data_ACP$index <- NULL

# On retire les données faiblement corellé
data_ACP$nbTags <- NULL
data_ACP$nbWords <- NULL
data_ACP$nbLinks <- NULL

# Ajout du ratio de like et dislike
data_ACP$ratioLikes <- data_ACP$nbLikes/(data_ACP$nbLikes + data_ACP$nbDislikes)
data_ACP$ratioDislikes <- data_ACP$nbDislikes/(data_ACP$nbLikes + data_ACP$nbDislikes)

data_ACP$nbLikes <- NULL
data_ACP$nbDislikes <- NULL

res.pca = PCA(data_ACP, scale.unit=TRUE, ncp=6, graph=T) 
```

# ACM
```{r}
data_ACM = data[1:50,]
i=0
while(i<ncol(data_ACM)){
  i=i+1
  data_ACM[,i]=as.factor(data_ACM[,i])
}
data_ACM$nbTags <- NULL
data_ACM$nbWords <- NULL
data_ACM$nbLinks <- NULL
res.mca = MCA(data_ACM, quali.sup = c(7,8,10), graph = TRUE)
plot.MCA(res.mca, invisible=c("var"), cex=0.35)
```

# AFC
```{r}
data_AFC = data
res.afc = CA(data_AFC[, c(2:5 ,12:13)])
```


